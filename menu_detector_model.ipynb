{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO8DIoGCIUNgjGD1hohDOdN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ismoil27/computer_vision/blob/main/menu_detector_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKMguGD5l79T",
        "outputId": "51cd7666-30b9-42a2-d249-1e11cad05f63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Menu Detector!\n"
          ]
        }
      ],
      "source": [
        "print('Menu Detector!')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Import Libraries\n",
        "# -------------------------\n",
        "from google.colab import drive\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import mobilenet_v2\n",
        "\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "RKkChIFH-MLI"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Mbcvbyj_WCB",
        "outputId": "d788689d-dce9-416d-d508-c999a851ed06"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Dataset Path\n",
        "\n",
        "DATASET_PATH = '/content/drive/MyDrive/food101_dataset'\n",
        "print('Dataset_path:', DATASET_PATH)\n",
        "\n",
        "\n",
        "\n",
        "CUSTOM_CLASS_MAPPING = {\n",
        "    \"hamburger\": \"hamburger\",\n",
        "    \"hot_dog\": \"hot_dog\",\n",
        "    \"chocolate_cake\": \"dessert\", # label grouping | class consolidation\n",
        "    \"cheesecake\": \"dessert\",     # label grouping | class consolidation\n",
        "    \"kebab\": \"kebab\",\n",
        "    \"pilaf\": \"pilaf\"\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "CLASSES = ['hamburger', 'hot_dog', 'dessert', 'kebab', 'pilaf']\n",
        "CLASS_TO_IDX = {cls: i for i, cls in enumerate(CLASSES)}\n",
        "NUM_CLASSES = len(CLASSES)\n",
        "\n",
        "print(NUM_CLASSES)\n",
        "print(CLASS_TO_IDX)\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXf_dcqf_0F2",
        "outputId": "c19e15b7-03e4-4c3a-ffeb-7f404a2f051b"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset_path: /content/drive/MyDrive/food101_dataset\n",
            "5\n",
            "{'hamburger': 0, 'hot_dog': 1, 'dessert': 2, 'kebab': 3, 'pilaf': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Custom Dataset Class\n",
        "# -----------------------\n",
        "\n",
        "class FoodDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        # print('images_length', len(self.images))\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.images[idx]\n",
        "        # print('image_path', img_path)\n",
        "        label = self.labels[idx]\n",
        "        # print('label', label)\n",
        "        try:\n",
        "            image = Image.open(img_path)\n",
        "            if image.mode == \"P\" or image.mode == \"RGBA\":\n",
        "                image = image.convert(\"RGBA\").convert(\"RGB\")\n",
        "            else:\n",
        "                image = image.convert(\"RGB\")\n",
        "        except (UnidentifiedImageError, OSError):\n",
        "            print(f\"Skipping broken image: {img_path}\")\n",
        "            return self.__getitem__((idx + 1) % len(self.images)) #\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n"
      ],
      "metadata": {
        "id": "Vik8RvJalsu-"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# Gather and Split Data\n",
        "# --------------------------\n",
        "all_images = []\n",
        "for original_class, mapped_class in CUSTOM_CLASS_MAPPING.items():\n",
        "    class_path = os.path.join(DATASET_PATH, original_class) # /content/drive/MyDrive/food101_dataset/hamburger\n",
        "    print('class_path:', class_path)\n",
        "    if not os.path.exists(class_path):\n",
        "        print(f\"Warning: {class_path} not found\")\n",
        "        continue\n",
        "    for img in os.listdir(class_path):\n",
        "        if img.endswith(('.jpg', '.jpeg', '.png')): # .txt, .docx\n",
        "            full_path = os.path.join(class_path, img) # /content/drive/MyDrive/food101_dataset/hamburger/100057.jpg\n",
        "            all_images.append((full_path, CLASS_TO_IDX[mapped_class]))\n",
        "\n",
        "np.random.shuffle(all_images)\n",
        "split = int(0.8 * len(all_images))\n",
        "train_data = all_images[:split] # 1000 | 800 train_data | 200 val_data\n",
        "val_data = all_images[split:]\n",
        "\n",
        "train_images, train_labels = zip(*train_data)\n",
        "val_images, val_labels = zip(*val_data)\n",
        "\n",
        "# print('all_images:', all_images)\n",
        "\n",
        "dataset = FoodDataset(train_images, train_labels)\n",
        "print(len(dataset))\n",
        "img, lbl = dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cB-VKWmAod0t",
        "outputId": "0f86dc8c-694c-4039-b03b-be45c3cd5879"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class_path: /content/drive/MyDrive/food101_dataset/hamburger\n",
            "class_path: /content/drive/MyDrive/food101_dataset/hot_dog\n",
            "class_path: /content/drive/MyDrive/food101_dataset/chocolate_cake\n",
            "class_path: /content/drive/MyDrive/food101_dataset/cheesecake\n",
            "class_path: /content/drive/MyDrive/food101_dataset/kebab\n",
            "class_path: /content/drive/MyDrive/food101_dataset/pilaf\n",
            "3278\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = FoodDataset(train_images, train_labels, transform=transform)\n",
        "val_dataset = FoodDataset(val_images, val_labels, transform=transform)"
      ],
      "metadata": {
        "id": "dLUmRiAYpi6h"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2) #thread | parallel loading for speed\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "-VjHnd0CqjKk"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pretrained model\n",
        "model = mobilenet_v2(weights=\"IMAGENET1K_V1\") # pretrained model | ligthweight | CNN | 1000 class | million\n",
        "model.classifier[1] = nn.Linear(model.classifier[1].in_features, NUM_CLASSES) # fine-tuning | backbone | model layer freeze"
      ],
      "metadata": {
        "id": "x8Ch0sCisilt"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('device', device)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbBm7DH7mQ_m",
        "outputId": "b342c545-7421-4311-c693-76bf7ccaddfb"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss() # Loss Function | '70%' burger, '30%' pilaf\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001) # weight\n",
        "torch.backends.cudnn.benchmark = True # Benchmark Setting | Trick | 10%-20%"
      ],
      "metadata": {
        "id": "DuoyeKlWngjs"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------\n",
        "# Training Loop\n",
        "# --------------\n",
        "\n",
        "NUM_EPOCHS = 10\n",
        "best_accuracy = 0.0\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  model.train() # train mode\n",
        "  running_loss = 0.0\n",
        "  for images, labels in train_loader: # Forward and Backward(Backpropagation)\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    optimizer.zero_grad() # zero the gradient\n",
        "    outputs = model(images) # Forward Pass | Dog | 5 Classes\n",
        "    loss = criterion(outputs, labels) # Calculate Loss\n",
        "    loss.backward()\n",
        "    optimizer.step() # Adam optimizer\n",
        "    running_loss += loss.item() # Track Loss\n",
        "\n",
        "  # Validation\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "      for images, labels in val_loader:\n",
        "          images, labels = images.to(device), labels.to(device)\n",
        "          outputs = model(images)\n",
        "          _, predicted = torch.max(outputs, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "  val_acc = 100 * correct / total # Calculate Validation Accuracy\n",
        "  print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] Loss: {running_loss/len(train_loader):.4f}, Val Accuracy: {val_acc:.2f}%\")\n",
        "\n",
        "  if val_acc > best_accuracy:\n",
        "      best_accuracy = val_acc\n",
        "      torch.save(model.state_dict(), '/content/menu_detector.pth')\n",
        "      print(\"Saved new best model!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyaEhbiq1CbN",
        "outputId": "87ec6c5b-28e2-4445-fe37-ab303d64d4a7"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] Loss: 0.4577, Val Accuracy: 89.76%\n",
            "Saved new best model!\n",
            "Epoch [2/10] Loss: 0.2593, Val Accuracy: 89.27%\n",
            "Epoch [3/10] Loss: 0.2076, Val Accuracy: 89.88%\n",
            "Saved new best model!\n",
            "Epoch [4/10] Loss: 0.1903, Val Accuracy: 89.15%\n",
            "Epoch [5/10] Loss: 0.1630, Val Accuracy: 90.61%\n",
            "Saved new best model!\n",
            "Epoch [6/10] Loss: 0.1409, Val Accuracy: 90.37%\n",
            "Epoch [7/10] Loss: 0.1096, Val Accuracy: 89.02%\n",
            "Epoch [8/10] Loss: 0.1410, Val Accuracy: 90.37%\n",
            "Epoch [9/10] Loss: 0.0888, Val Accuracy: 90.00%\n",
            "Epoch [10/10] Loss: 0.0909, Val Accuracy: 91.34%\n",
            "Saved new best model!\n"
          ]
        }
      ]
    }
  ]
}