{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOllmISJIvGchjd1ViOXQYQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ismoil27/computer_vision/blob/main/menu_detector_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKMguGD5l79T",
        "outputId": "4ddc6217-3bbe-417c-8f3a-99912b0c22ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Menu Detector!\n"
          ]
        }
      ],
      "source": [
        "print('Menu Detector!')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Import Libraries\n",
        "# -------------------------\n",
        "from google.colab import drive\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import mobilenet_v2\n",
        "\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "RKkChIFH-MLI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Mbcvbyj_WCB",
        "outputId": "fb835783-9dc3-4182-94f1-e5c4c31fabf9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Dataset Path\n",
        "\n",
        "DATASET_PATH = '/content/drive/MyDrive/food101_dataset'\n",
        "print('Dataset_path:', DATASET_PATH)\n",
        "\n",
        "\n",
        "\n",
        "CUSTOM_CLASS_MAPPING = {\n",
        "    \"hamburger\": \"hamburger\",\n",
        "    \"hot_dog\": \"hot_dog\",\n",
        "    \"chocolate_cake\": \"dessert\", # label grouping | class consolidation\n",
        "    \"cheesecake\": \"dessert\",     # label grouping | class consolidation\n",
        "    \"kebab\": \"kebab\",\n",
        "    \"pilaf\": \"pilaf\"\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "CLASSES = ['hamburger', 'hot_dog', 'dessert', 'kebab', 'pilaf']\n",
        "CLASS_TO_IDX = {cls: i for i, cls in enumerate(CLASSES)}\n",
        "NUM_CLASSES = len(CLASSES)\n",
        "\n",
        "print(NUM_CLASSES)\n",
        "print(CLASS_TO_IDX)\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXf_dcqf_0F2",
        "outputId": "e6af02ea-21d9-4cc4-bad8-e2341d64c869"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset_path: /content/drive/MyDrive/food101_dataset\n",
            "5\n",
            "{'hamburger': 0, 'hot_dog': 1, 'dessert': 2, 'kebab': 3, 'pilaf': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# Custom Dataset Class\n",
        "# -----------------------\n",
        "\n",
        "class FoodDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        print('images_length', len(self.images))\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.images[idx]\n",
        "        print('image_path', img_path)\n",
        "        label = self.labels[idx]\n",
        "        print('label', label)\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('RGB') # 3 Channel\n",
        "        except (UnidentifiedImageError, OSError):\n",
        "            print(f\"Skipping broken image: {img_path}\")\n",
        "            return self.__getitem__((idx + 1) % len(self.images)) #\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n"
      ],
      "metadata": {
        "id": "Vik8RvJalsu-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# Gather and Split Data\n",
        "# --------------------------\n",
        "all_images = []\n",
        "for original_class, mapped_class in CUSTOM_CLASS_MAPPING.items():\n",
        "    class_path = os.path.join(DATASET_PATH, original_class) # /content/drive/MyDrive/food101_dataset/hamburger\n",
        "    print('class_path:', class_path)\n",
        "    if not os.path.exists(class_path):\n",
        "        print(f\"Warning: {class_path} not found\")\n",
        "        continue\n",
        "    for img in os.listdir(class_path):\n",
        "        if img.endswith(('.jpg', '.jpeg', '.png')): # .txt, .docx\n",
        "            full_path = os.path.join(class_path, img) # /content/drive/MyDrive/food101_dataset/hamburger/100057.jpg\n",
        "            all_images.append((full_path, CLASS_TO_IDX[mapped_class]))\n",
        "\n",
        "np.random.shuffle(all_images)\n",
        "split = int(0.8 * len(all_images))\n",
        "train_data = all_images[:split] # 1000 | 800 train_data | 200 val_data\n",
        "val_data = all_images[split:]\n",
        "\n",
        "train_images, train_labels = zip(*train_data)\n",
        "val_images, val_labels = zip(*val_data)\n",
        "\n",
        "# print('all_images:', all_images)\n",
        "\n",
        "dataset = FoodDataset(train_images, train_labels)\n",
        "print(len(dataset))\n",
        "img, lbl = dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cB-VKWmAod0t",
        "outputId": "f120d189-76b8-46fd-c8d7-e89f4851850c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class_path: /content/drive/MyDrive/food101_dataset/hamburger\n",
            "class_path: /content/drive/MyDrive/food101_dataset/hot_dog\n",
            "class_path: /content/drive/MyDrive/food101_dataset/chocolate_cake\n",
            "class_path: /content/drive/MyDrive/food101_dataset/cheesecake\n",
            "class_path: /content/drive/MyDrive/food101_dataset/kebab\n",
            "class_path: /content/drive/MyDrive/food101_dataset/pilaf\n",
            "images_length 3278\n",
            "3278\n",
            "image_path /content/drive/MyDrive/food101_dataset/chocolate_cake/1076899.jpg\n",
            "label 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = FoodDataset(train_images, train_labels, transform=transform)\n",
        "val_dataset = FoodDataset(val_images, val_labels, transform=transform)"
      ],
      "metadata": {
        "id": "dLUmRiAYpi6h"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2) #thread | parallel loading for speed\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VjHnd0CqjKk",
        "outputId": "76f47440-1cd2-4471-8663-8da1475aadf4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "images_length 3278\n",
            "images_length 3278\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pretrained model\n",
        "model = mobilenet_v2(weights=\"IMAGENET1K_V1\") # pretrained model | ligthweight | CNN | 1000 class | million\n",
        "model.classifier[1] = nn.Linear(model.classifier[1].in_features, NUM_CLASSES) # fine-tuning | backbone | model layer freeze"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8Ch0sCisilt",
        "outputId": "b677b52b-c3bf-4f6e-da3b-83a79d0fd7fa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 71.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('device', device)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbBm7DH7mQ_m",
        "outputId": "529cf446-1649-4026-ec4f-0a894581dfc5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss() # Loss Function | '70%' burger, '30%' pilaf\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001) # weight\n",
        "torch.backends.cudnn.benchmark = True # Benchmark Setting | Trick | 10%-20%"
      ],
      "metadata": {
        "id": "DuoyeKlWngjs"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}